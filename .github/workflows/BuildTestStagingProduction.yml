name: CI/CD Pipeline

on:
  push:
    branches:
      - main
      - staging
  pull_request:
    branches:
      - main
      - staging

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyspark requests  # Agrega cualquier otra librería necesaria

  DataExtraction:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Run data extraction
        run: python App/Data/Raw-Data/Trigger.py  # Ejecuta el script para generar el CSV

      - name: Upload CSV as artifact
        uses: actions/upload-artifact@v3
        with:
          name: adult_data_csv  # Nombre del artefacto
          path: App/Data/Raw-Data/adult_data.csv  # Asegúrate de que esta sea la ruta correcta

  test:
    runs-on: ubuntu-latest
    needs: DataExtraction
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Download CSV artifact
        uses: actions/download-artifact@v3
        with:
          name: adult_data_csv
          path: App/Data/Raw-Data/  # Asegúrate de que esta ruta coincida con donde se necesita el archivo

      - name: Run tests using the CSV
        run: |
          python -c "import pandas as pd; df = pd.read_csv('App/Data/Raw-Data/adult_data.csv'); print(df.head())"

  staging:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/staging'
    steps:
      - name: Deploy to Staging
        run: echo "Deploying to Staging environment"

  production:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to Production
        run: echo "Deploying to Production environment"
